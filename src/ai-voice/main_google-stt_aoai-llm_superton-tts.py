#!/usr/bin/env python3
"""
Google Cloud Speech-to-Text + Azure OpenAI LLM + SuperTone TTS ìŒì„± ì–´ì‹œìŠ¤í„´íŠ¸
ë¼ì¦ˆë² ë¦¬íŒŒì´ ì œë¡œ WH (Python 3.7.3) í˜¸í™˜

Google Cloud Speech-to-Text API ì‚¬ìš© (VAD ë‚´ì¥)
SuperTone APIë¥¼ ì‚¬ìš©í•œ TTS
Azure OpenAIë¥¼ ì‚¬ìš©í•œ LLM
"""

import io
import json
import logging
import os
import subprocess
import sys
import threading
import time

# í•œê¸€ ì¶œë ¥ ê¹¨ì§ ë°©ì§€ (Python 3.7.3 í˜¸í™˜)
if hasattr(sys.stdout, "reconfigure"):
    try:
        sys.stdout.reconfigure(encoding="utf-8")
    except (AttributeError, ValueError):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
else:
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")

# ê²½ë¡œ ì„¤ì •
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

try:
    from dotenv import load_dotenv
except ImportError:
    print("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip3 install python-dotenv")
    sys.exit(1)

# AIY Projects ëª¨ë“ˆ
try:
    from aiy.board import Board, Led

    HAS_BOARD = True
except ImportError:
    HAS_BOARD = False
    print("ê²½ê³ : AIY Projects board ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

try:
    from aiy.cloudspeech import CloudSpeechClient

    HAS_CLOUDSPEECH = True
except ImportError:
    HAS_CLOUDSPEECH = False
    print("âŒ aiy.cloudspeech ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("AIY Projectsê°€ ì„¤ì¹˜ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    sys.exit(1)


logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ============================================================================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ============================================================================

# .env íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
current_dir = os.path.dirname(os.path.abspath(__file__))
config_path = os.path.join(current_dir, "config", ".env")
if os.path.exists(config_path):
    load_dotenv(config_path)
else:
    # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
    parent_config = os.path.join(os.path.dirname(current_dir), "config", ".env")
    if os.path.exists(parent_config):
        load_dotenv(parent_config)
    else:
        # ê¸°ë³¸ ê²½ë¡œ
        load_dotenv()

# SuperTone ì„¤ì • (TTSìš©)
SUPERTON_API_KEY = os.environ.get("SUPERTON_API_KEY")
SUPERTON_VOICE_ID = os.environ.get("SUPERTON_VOICE_ID")

# íŠ¸ë¦¬ê±° ë‹¨ì–´ ì„¤ì • (Wake word)
TRIGGER_WORDS = os.environ.get("TRIGGER_WORDS", "ì¹˜í”¼")

# íŠ¸ë¦¬ê±° ë‹¨ì–´ ì‚¬ìš© ì—¬ë¶€ (Falseë©´ íŠ¸ë¦¬ê±° ë‹¨ì–´ ì—†ì´ ë°”ë¡œ ì‹œì‘)
USE_TRIGGER_WORD = os.environ.get("USE_TRIGGER_WORD", "true").lower() in (
    "true",
    "1",
    "yes",
)

# Sleep mode íƒ€ì„ì•„ì›ƒ ì„¤ì •
SLEEP_TIMEOUT = float(os.environ.get("SLEEP_TIMEOUT", "10.0"))

# Google Cloud Speech ì–¸ì–´ ì½”ë“œ
GOOGLE_SPEECH_LANGUAGE = os.environ.get("GOOGLE_SPEECH_LANGUAGE", "ko_KR")

# ì–¼êµ´ í‘œì • ì œì–´ ì„¤ì •
DEVICE_SERIAL = os.environ.get("DEVICE_SERIAL")
SERVER_URL = os.environ.get(
    "SERVER_URL", "https://chytonpide.azurewebsites.net"
)  # ê¸°ë³¸ê°’: í”„ë¡œë•ì…˜ ì„œë²„ URL

# ê²€ì¦
if not SUPERTON_API_KEY or not SUPERTON_VOICE_ID:
    logger.error(
        "SUPERTON_API_KEYì™€ SUPERTON_VOICE_IDê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
    )
    sys.exit(1)

# ============================================================================
# SuperTone TTS (REST API)
# ============================================================================

try:
    import requests

    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False
    print("requestsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip3 install requests")
    sys.exit(1)

try:
    import tempfile
except ImportError:
    print("tempfile ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

# AIY Projects audio ëª¨ë“ˆ (TTS ì¬ìƒìš©)
try:
    from aiy.voice.audio import play_wav

    HAS_AIY_AUDIO = True
except ImportError:
    HAS_AIY_AUDIO = False
    print("ê²½ê³ : AIY Projects audio ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


class SupertonTTS:
    """SuperTone APIë¥¼ ì‚¬ìš©í•œ TTS í´ë˜ìŠ¤ (AIY Projects play_wav ì‚¬ìš©)"""

    def __init__(self, voice_id=None, api_key=None):
        """
        ì´ˆê¸°í™”

        Args:
            voice_id: ìŒì„± ID (ê¸°ë³¸ê°’: envì˜ SUPERTON_VOICE_ID)
            api_key: API í‚¤ (ê¸°ë³¸ê°’: envì˜ SUPERTON_API_KEY)
        """
        self.api_key = api_key or SUPERTON_API_KEY
        self.voice_id = voice_id or SUPERTON_VOICE_ID

        if not self.api_key:
            raise ValueError("âŒ SUPERTON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        logger.info("SuperTone TTS ì´ˆê¸°í™” ì™„ë£Œ (ìŒì„± ID: %s)", self.voice_id)

    def generate(
        self,
        text,
        language="ko",
        style="neutral",
        output_format="wav",
        pitch_shift=0,
        speed=1,
        pitch_variance=1,
    ):
        """
        SuperTone APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ìƒì„±

        Args:
            text: í…ìŠ¤íŠ¸
            language: ì–¸ì–´ (ê¸°ë³¸ê°’: "ko")
            style: ìŠ¤íƒ€ì¼ (ê¸°ë³¸ê°’: "neutral")
            output_format: ì¶œë ¥ í˜•ì‹ - "wav" ë˜ëŠ” "mp3" (ê¸°ë³¸ê°’: "wav")
            pitch_shift: ìŒë†’ì´ ì¡°ì • (-20 ~ 20, ê¸°ë³¸ê°’: 0)
            speed: ì¬ìƒ ì†ë„ (0.5 ~ 2, ê¸°ë³¸ê°’: 1)
            pitch_variance: ìŒë†’ì´ ë³€ë™ì„± (0 ~ 2, ê¸°ë³¸ê°’: 1)

        Returns:
            ìŒì„± ë°”ì´íŠ¸ ë°ì´í„° ë˜ëŠ” None
        """
        url = f"https://supertoneapi.com/v1/text-to-speech/{self.voice_id}"

        headers = {"x-sup-api-key": self.api_key, "Content-Type": "application/json"}

        payload = {
            "text": text,
            "language": language,
            "style": style,
            "model": "sona_speech_1",
            "output_format": output_format,
            "voice_settings": {
                "pitch_shift": pitch_shift,
                "pitch_variance": pitch_variance,
                "speed": speed,
            },
        }

        try:
            logger.debug(f"SuperTone ìŒì„± ìƒì„± ì¤‘: {text[:20]}...")
            response = requests.post(url, json=payload, headers=headers, timeout=30)

            if response.status_code == 200:
                logger.debug("SuperTone ìŒì„± ìƒì„± ì™„ë£Œ")
                return response.content
            else:
                logger.error(
                    f"SuperTone API ì˜¤ë¥˜ (ìƒíƒœ: {response.status_code}): {response.text}"
                )
                return None

        except requests.exceptions.Timeout:
            logger.error("SuperTone ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (30ì´ˆ)")
            return None
        except Exception as e:
            logger.error(f"SuperTone ì˜¤ë¥˜: {e}", exc_info=True)
            return None

    def speak(
        self,
        text,
        language="ko",
        style="neutral",
        pitch_shift=0,
        speed=1,
        pitch_variance=1,
    ):
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒ (AIY Projects play_wav ì‚¬ìš©)

        Args:
            text: ë§í•  í…ìŠ¤íŠ¸
            language: ì–¸ì–´ (ê¸°ë³¸ê°’: "ko")
            style: ìŠ¤íƒ€ì¼ (ê¸°ë³¸ê°’: "neutral")
            pitch_shift: ìŒë†’ì´ ì¡°ì • (-20 ~ 20, ê¸°ë³¸ê°’: 0)
            speed: ì¬ìƒ ì†ë„ (0.5 ~ 2, ê¸°ë³¸ê°’: 1)
            pitch_variance: ìŒë†’ì´ ë³€ë™ì„± (0 ~ 2, ê¸°ë³¸ê°’: 1)
        """
        audio_data = self.generate(
            text,
            language,
            style,
            output_format="wav",
            pitch_shift=pitch_shift,
            speed=speed,
            pitch_variance=pitch_variance,
        )

        if audio_data:
            try:
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(
                    suffix=".wav", delete=False
                ) as tmp_file:
                    tmp_file.write(audio_data)
                    tmp_file_path = tmp_file.name

                try:
                    # ì¬ìƒ (AIY Projects play_wav ì‚¬ìš©)
                    if HAS_AIY_AUDIO:
                        play_wav(tmp_file_path)
                    else:
                        import subprocess

                        subprocess.run(["aplay", "-q", tmp_file_path], check=True)

                    logger.debug("SuperTone ìŒì„± ì¶œë ¥ ì™„ë£Œ")
                finally:
                    try:
                        os.unlink(tmp_file_path)
                    except Exception:
                        pass

            except Exception as e:
                logger.error(f"SuperTone ì¬ìƒ ì˜¤ë¥˜: {e}", exc_info=True)


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

# ìƒëŒ€ ê²½ë¡œë¡œ import ì‹œë„ (í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
try:
    from core.chipi_brain import ChipiBrain
except ImportError:
    # ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì‹œë„
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(current_dir)
        if parent_dir not in sys.path:
            sys.path.insert(0, parent_dir)
        from core.chipi_brain import ChipiBrain
    except ImportError:
        # ìµœìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì‹œë„
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            parent_dir = os.path.dirname(os.path.dirname(current_dir))
            if parent_dir not in sys.path:
                sys.path.insert(0, parent_dir)
            from core.chipi_brain import ChipiBrain
        except ImportError as e:
            print(f"âŒ ChipiBrainì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            sys.exit(1)

# ìƒìˆ˜ import
try:
    from constants import (
        EMOTION_CHECK_ORDER,
        EMOTION_DEFAULT,
        EMOTION_KEYWORDS,
        EXIT_COMMANDS,
        LED_OFF_KEYWORDS,
        LED_ON_KEYWORDS,
        SAD_TONE_KEYWORDS,
        SERVO_KEYWORDS,
        SLEEP_COMMANDS,
    )
except ImportError:
    # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì‹œë„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    if current_dir not in sys.path:
        sys.path.insert(0, current_dir)
    from constants import (
        EMOTION_CHECK_ORDER,
        EMOTION_DEFAULT,
        EMOTION_KEYWORDS,
        EXIT_COMMANDS,
        LED_OFF_KEYWORDS,
        LED_ON_KEYWORDS,
        SAD_TONE_KEYWORDS,
        SERVO_KEYWORDS,
        SLEEP_COMMANDS,
    )


def load_voice_hints():
    """voice_hints.json íŒŒì¼ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë¬¸ì¥ ë¡œë“œ"""
    current_dir = os.path.dirname(os.path.abspath(__file__))
    hints_file = os.path.join(current_dir, "config", "voice_hints.json")

    # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œë„ ì°¾ê¸°
    if not os.path.exists(hints_file):
        parent_config = os.path.join(
            os.path.dirname(current_dir), "config", "voice_hints.json"
        )
        if os.path.exists(parent_config):
            hints_file = parent_config

    if os.path.exists(hints_file):
        try:
            with open(hints_file, "r", encoding="utf-8") as f:
                data = json.load(f)
                return data.get("common_phrases", [])
        except Exception as e:
            logger.warning(f"voice_hints.json íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            return []
    else:
        logger.debug(f"voice_hints.json íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {hints_file}")
        return []


def get_hints(language_code, trigger_words=None):
    """ì–¸ì–´ ì½”ë“œì— ë”°ë¥¸ íŒíŠ¸ êµ¬ë¬¸ ë°˜í™˜

    Args:
        language_code: ì–¸ì–´ ì½”ë“œ
        trigger_words: íŠ¸ë¦¬ê±° ë‹¨ì–´ ë¦¬ìŠ¤íŠ¸ (ì˜µì…˜)
    """
    if language_code.startswith("ko_"):
        hints = []

        # 1. íŠ¸ë¦¬ê±° ë‹¨ì–´ ê¸°ë°˜ íŒíŠ¸
        if trigger_words:
            # ê¸°ë³¸ íŠ¸ë¦¬ê±° ë‹¨ì–´ë“¤
            hints.extend(trigger_words)
            # íŠ¸ë¦¬ê±° ë‹¨ì–´ + í˜¸ê²© ì¡°ì‚¬ (ì•¼, ì•„, ì´ì—¬ ë“±)
            for word in trigger_words:
                hints.append(f"{word}ì•¼")
                hints.append(f"{word}ì•„")
                hints.append(f"{word}ì´")
            # íŠ¸ë¦¬ê±° ë‹¨ì–´ + ì¼ë°˜ì ì¸ ëª…ë ¹ì–´ (ì§§ì€ ìŒì„± ì¸ì‹ í–¥ìƒ)
            for word in trigger_words:
                hints.append(f"{word}ì•¼ ì•ˆë…•")
                hints.append(f"{word}ì•¼ ë­í•´")
                hints.append(f"{word}ì•¼ ì˜ìˆì–´")

        # 2. JSON íŒŒì¼ì—ì„œ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë¬¸ì¥ ë¡œë“œ
        common_phrases = load_voice_hints()
        if common_phrases:
            hints.extend(common_phrases)
            logger.info(
                f"JSON íŒŒì¼ì—ì„œ {len(common_phrases)}ê°œì˜ íŒíŠ¸ ë¬¸ì¥ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤."
            )

        if hints:
            return tuple(set(hints))  # ì¤‘ë³µ ì œê±°
        return None
    return None


def _contains_trigger_word(text, trigger_words):
    """í…ìŠ¤íŠ¸ì— íŠ¸ë¦¬ê±° ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸ (ìœ ì—°í•œ ë§¤ì¹­)

    ì§§ì€ ìŒì„±("ì¹˜í”¼ì•¼" ë“±)ë„ ì˜ ì¸ì‹ë˜ë„ë¡ ë¶€ë¶„ ë§¤ì¹­ ì§€ì›
    """
    if not text or not trigger_words:
        return False

    text_lower = text.lower().strip()

    # ì™„ì „ ì¼ì¹˜ ë˜ëŠ” í¬í•¨ í™•ì¸
    for trigger in trigger_words:
        trigger_lower = trigger.lower()
        if trigger_lower in text_lower:
            return True

        # ë¶€ë¶„ ë§¤ì¹­: íŠ¸ë¦¬ê±° ë‹¨ì–´ê°€ í…ìŠ¤íŠ¸ì˜ ì‹œì‘ ë¶€ë¶„ì— ìˆëŠ”ì§€ í™•ì¸
        # ì˜ˆ: "ì¹˜í”¼ì•¼" -> "ì¹˜í”¼" ë§¤ì¹­
        if text_lower.startswith(trigger_lower):
            return True

        # í˜¸ê²© ì¡°ì‚¬ í¬í•¨ í™•ì¸: "ì¹˜í”¼ì•¼", "ì¹˜í”¼ì•„", "ì¹˜í”¼ì´" ë“±
        for suffix in ["ì•¼", "ì•„", "ì´", "ì—¬", "ì´ì•¼", "ì´ì—¬"]:
            if text_lower.startswith(trigger_lower + suffix):
                return True

    return False


def _find_servo_script_path():
    """ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ì°¾ê¸°"""
    # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì°¾ê¸°
    main_file_dir = os.path.dirname(os.path.abspath(__file__))
    main_file_parent = os.path.dirname(main_file_dir)

    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ ì‹œë„
    possible_paths = [
        # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ (src/ai-voice/servo/examples/plant_shaker.py)
        os.path.join(main_file_dir, "servo", "examples", "plant_shaker.py"),
        # ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€
        os.path.join(main_file_parent, "servo", "examples", "plant_shaker.py"),
        # í™ˆ ë””ë ‰í† ë¦¬ ê¸°ì¤€ (~/chytonpide/servo/examples/plant_shaker.py)
        os.path.expanduser("~/chytonpide/servo/examples/plant_shaker.py"),
        # ì ˆëŒ€ ê²½ë¡œ (ë¼ì¦ˆë² ë¦¬íŒŒì´ ê¸°ë³¸ ê²½ë¡œ)
        "/home/pi/chytonpide/servo/examples/plant_shaker.py",
    ]

    for path in possible_paths:
        abs_path = os.path.abspath(os.path.expanduser(path))
        if os.path.exists(abs_path):
            logger.info(f"ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ì°¾ìŒ: {abs_path}")
            return abs_path

    logger.warning("ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ê²½ë¡œ:")
    for path in possible_paths:
        logger.warning(f"  - {os.path.abspath(os.path.expanduser(path))}")
    return None


def _run_servo_plant_shake():
    """ì„œë³´ ëª¨í„°ë¡œ í™”ë¶„ í”ë“¤ê¸° ì‹¤í–‰ (subprocess ì‚¬ìš©, ë¹„ë¸”ë¡œí‚¹)"""
    script_path = _find_servo_script_path()
    if not script_path:
        logger.error("ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    try:
        logger.info(f"ì„œë³´ ëª¨í„° ì‹¤í–‰: {script_path}")
        # sudo ê¶Œí•œìœ¼ë¡œ ë¹„ë¸”ë¡œí‚¹ ì‹¤í–‰ (Popen ì‚¬ìš©)
        process = subprocess.Popen(
            ["sudo", "python3", script_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
        )
        # í”„ë¡œì„¸ìŠ¤ê°€ ì‹œì‘ë˜ë©´ ì¦‰ì‹œ ë°˜í™˜ (ë¹„ë¸”ë¡œí‚¹)
        logger.debug(f"ì„œë³´ ëª¨í„° í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¨ (PID: {process.pid})")

        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì™„ë£Œ ëŒ€ê¸°
        def _wait_for_completion():
            try:
                stdout, stderr = process.communicate(timeout=30)
                if process.returncode == 0:
                    logger.info("ì„œë³´ ëª¨í„° ì‹¤í–‰ ì™„ë£Œ")
                    if stdout:
                        logger.debug(f"ì„œë³´ ì¶œë ¥: {stdout}")
                else:
                    logger.error(f"ì„œë³´ ëª¨í„° ì‹¤í–‰ ì‹¤íŒ¨ (ì½”ë“œ: {process.returncode})")
                    if stderr:
                        logger.error(f"ì„œë³´ ì˜¤ë¥˜: {stderr}")
            except subprocess.TimeoutExpired:
                logger.error("ì„œë³´ ëª¨í„° ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (30ì´ˆ)")
                process.kill()
                process.wait()
            except Exception as e:
                logger.error(f"ì„œë³´ ëª¨í„° ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)

        # ì™„ë£Œ ëŒ€ê¸°ë¥¼ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        threading.Thread(target=_wait_for_completion, daemon=True).start()

        return True

    except Exception as e:
        logger.error(f"ì„œë³´ ëª¨í„° ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
        return False


def _run_servo_async():
    """ì„œë³´ ëª¨í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)"""

    def _servo_worker():
        try:
            _run_servo_plant_shake()
        except Exception as e:
            logger.error(f"ì„œë³´ ëª¨í„° ë¹„ë™ê¸° ì‹¤í–‰ ì˜¤ë¥˜: {e}")

    thread = threading.Thread(target=_servo_worker, daemon=True)
    thread.start()
    logger.info("ì„œë³´ ëª¨í„° ë¹„ë™ê¸° ì‹¤í–‰ ì‹œì‘")
    return thread


# ì˜¤ë””ì˜¤ ìœ í‹¸ë¦¬í‹° import
try:
    from utils.audio_utils import (
        find_mapped_audio,
        load_audio_mapping,
        play_audio_file,
        play_audio_file_async,
        play_audio_file_by_path,
        play_intro_audio,
    )
except ImportError:
    # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ì‹œë„
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        if current_dir not in sys.path:
            sys.path.insert(0, current_dir)
        from utils.audio_utils import (
            find_mapped_audio,
            load_audio_mapping,
            play_audio_file,
            play_audio_file_async,
            play_audio_file_by_path,
            play_intro_audio,
        )
    except ImportError:
        logger.error("utils.audio_utilsë¥¼ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # í´ë°± í•¨ìˆ˜ ì •ì˜
        def play_intro_audio(*args, **kwargs):
            logger.error("play_intro_audio í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return False

        def load_audio_mapping():
            return {}

        def find_mapped_audio(user_text, audio_mapping):
            return None, None

        def play_audio_file(filename):
            return False

        def play_audio_file_async(filename):
            return None

        def play_audio_file_by_path(file_path):
            return False


def _contains_servo_keywords(text):
    """ì„œë³´ ëª¨í„° ì‹¤í–‰ í‚¤ì›Œë“œ ê°ì§€"""
    if not text:
        return False

    text_lower = text.lower()
    return any(keyword in text_lower for keyword in SERVO_KEYWORDS)


def _detect_face_emotion_from_response(text):
    """
    LLM ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ì–¼êµ´ í‘œì • ê°ì§€ (í‚¤ì›Œë“œ ê¸°ë°˜)

    Args:
        text: LLM ì‘ë‹µ í…ìŠ¤íŠ¸

    Returns:
        str: ê°ì • ìƒìˆ˜ ("HAPPY", "SAD", "ANGRY", "SURPRISED", "TIRED", "CALM", "DEFAULT")
    """
    if not text:
        return EMOTION_DEFAULT

    text_lower = text.lower()

    # ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ê°ì • ì²´í¬
    for emotion in EMOTION_CHECK_ORDER:
        keywords = EMOTION_KEYWORDS.get(emotion, [])
        if any(keyword in text_lower for keyword in keywords):
            logger.debug(f"ê°ì • ê°ì§€: {emotion} (í‚¤ì›Œë“œ ë§¤ì¹­)")
            return emotion

    # í‚¤ì›Œë“œê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ (NEUTRAL/DEFAULT)
    return EMOTION_DEFAULT


def _set_face_emotion(emotion, serial=None, server_url=None):
    """
    ì–¼êµ´ í‘œì • ì„¤ì •

    Args:
        emotion: ê°ì • ìƒìˆ˜ ("HAPPY", "SAD", "ANGRY", "SURPRISED", "TIRED", "CALM", "DEFAULT")
        serial: ë””ë°”ì´ìŠ¤ ì‹œë¦¬ì–¼ (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ DEVICE_SERIAL)
        server_url: ì„œë²„ URL (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ SERVER_URL)

    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    device_serial = serial or DEVICE_SERIAL
    if not device_serial:
        logger.warning("DEVICE_SERIALì´ ì„¤ì •ë˜ì§€ ì•Šì•„ ì–¼êµ´ í‘œì •ì„ ì„¤ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    url = f"{server_url or SERVER_URL}/devices/{device_serial}"
    # API ëª…ì„¸: lcd_face í•„ë“œë§Œ ë³´ë‚´ë©´ ë¨
    payload = {"lcd_face": emotion}

    try:
        # Content-Type: application/x-www-form-urlencoded (ê¸°ë³¸ê°’)
        response = requests.patch(url, data=payload, timeout=5)
        response.raise_for_status()

        logger.info(f"ì–¼êµ´ í‘œì • ì„¤ì • ì„±ê³µ: {emotion}")
        return True
    except requests.exceptions.RequestException as e:
        logger.warning(f"ì–¼êµ´ í‘œì • ì„¤ì • ì‹¤íŒ¨ ({emotion}): {e}")
        return False


def _contains_led_keywords(text):
    """LED ì œì–´ í‚¤ì›Œë“œ ê°ì§€

    Returns:
        str or None: "on", "off", ë˜ëŠ” None
    """
    if not text:
        return None

    text_lower = text.lower()

    # LED ì¼œê¸° í‚¤ì›Œë“œ í™•ì¸
    if any(keyword in text_lower for keyword in LED_ON_KEYWORDS):
        return "on"

    # LED ë„ê¸° í‚¤ì›Œë“œ í™•ì¸
    if any(keyword in text_lower for keyword in LED_OFF_KEYWORDS):
        return "off"

    return None


def _set_led_state(led_on, serial=None, server_url=None):
    """
    LED ìƒíƒœ ì„¤ì •

    Args:
        led_on: Trueë©´ ì¼œê¸°, Falseë©´ ë„ê¸°
        serial: ë””ë°”ì´ìŠ¤ ì‹œë¦¬ì–¼ (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ DEVICE_SERIAL)
        server_url: ì„œë²„ URL (ê¸°ë³¸ê°’: í™˜ê²½ ë³€ìˆ˜ SERVER_URL)

    Returns:
        bool: ì„±ê³µ ì—¬ë¶€
    """
    device_serial = serial or DEVICE_SERIAL
    if not device_serial:
        logger.warning("DEVICE_SERIALì´ ì„¤ì •ë˜ì§€ ì•Šì•„ LEDë¥¼ ì œì–´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    url = f"{server_url or SERVER_URL}/devices/{device_serial}"
    # API ëª…ì„¸: is_led_on í•„ë“œë§Œ ë³´ë‚´ë©´ ë¨ (ë¬¸ìì—´ë¡œ "true" ë˜ëŠ” "false")
    payload = {"is_led_on": "true" if led_on else "false"}

    try:
        # Content-Type: application/x-www-form-urlencoded (ê¸°ë³¸ê°’)
        response = requests.patch(url, data=payload, timeout=5)
        response.raise_for_status()

        state_str = "ì¼œê¸°" if led_on else "ë„ê¸°"
        logger.info(f"LED {state_str} ì„±ê³µ")
        return True
    except requests.exceptions.RequestException as e:
        state_str = "ì¼œê¸°" if led_on else "ë„ê¸°"
        logger.warning(f"LED {state_str} ì‹¤íŒ¨: {e}")
        return False


def main():
    device_serial = os.environ.get("DEVICE_SERIAL")
    if not device_serial:
        print("âš ï¸ DEVICE_SERIAL ì—†ìŒ")

    # íŠ¸ë¦¬ê±° ë‹¨ì–´ ì²˜ë¦¬
    trigger_words = []
    if USE_TRIGGER_WORD:
        trigger_words_str = TRIGGER_WORDS.strip()
        if "," in trigger_words_str:
            trigger_words = [w.strip().lower() for w in trigger_words_str.split(",")]
        elif " " in trigger_words_str:
            trigger_words = [w.strip().lower() for w in trigger_words_str.split()]
        else:
            trigger_words = [trigger_words_str.lower()]

        # ë¹ˆ ë‹¨ì–´ ì œê±°
        trigger_words = [w for w in trigger_words if w]
        if not trigger_words:
            trigger_words = ["ì¹˜í”¼"]

    print(
        "\n============== âš¡ ì¹˜í”¼(Chipi) Google STT + SuperTone TTS ëª¨ë“œ ì‹œì‘ ==============\n"
    )
    print(f"STT: Google Cloud Speech-to-Text (ì–¸ì–´: {GOOGLE_SPEECH_LANGUAGE})")
    print("LLM: Azure OpenAI")
    print("TTS: SuperTone")
    if USE_TRIGGER_WORD:
        print(f"íŠ¸ë¦¬ê±° ë‹¨ì–´: {', '.join(trigger_words)}")
        print(f"Sleep timeout: {SLEEP_TIMEOUT}ì´ˆ")
        print("Sleep modeì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤. íŠ¸ë¦¬ê±° ë‹¨ì–´ë¥¼ ë§í•˜ë©´ Wake modeë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
        print("Wake modeì—ì„œëŠ” íŠ¸ë¦¬ê±° ë‹¨ì–´ ì—†ì´ ëª¨ë“  ë§ì— ì‘ë‹µí•©ë‹ˆë‹¤.")
        print("ì¼ì • ì‹œê°„ ë™ì•ˆ ë§ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ Sleep modeë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
    else:
        print("íŠ¸ë¦¬ê±° ë‹¨ì–´: ì‚¬ìš© ì•ˆ í•¨ (ë°”ë¡œ ì‹œì‘)")
        print(f"Sleep timeout: {SLEEP_TIMEOUT}ì´ˆ")
        print("íŠ¸ë¦¬ê±° ë‹¨ì–´ ì—†ì´ ë°”ë¡œ ëª¨ë“  ë§ì— ì‘ë‹µí•©ë‹ˆë‹¤.")
        print("ì¼ì • ì‹œê°„ ë™ì•ˆ ë§ì´ ì—†ìœ¼ë©´ Sleep modeë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'ë¼ê³  ë§í•˜ê±°ë‚˜ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")

    def indicate_listening(is_listening):
        """ë“£ëŠ” ì¤‘ ìƒíƒœë¥¼ LEDë¡œ í‘œì‹œ"""
        if board and board.led:
            if is_listening:
                board.led.state = Led.ON
            else:
                board.led.state = Led.OFF

    try:
        # Board context manager ì‚¬ìš© (ì›ë³¸ ì˜ˆì œì™€ ë™ì¼ - ìŒì„± ì¸ì‹ ì„±ëŠ¥ í–¥ìƒ)
        # ì›ë³¸ ì˜ˆì œì²˜ëŸ¼ with Board() as board: í˜•íƒœë¡œ ì‚¬ìš©
        if HAS_BOARD:
            board_ctx = Board()
        else:
            from contextlib import nullcontext

            board_ctx = nullcontext()

        with board_ctx as board:
            print("ğŸŒ Google Cloud Speech-to-Text ì´ˆê¸°í™” ì¤‘...", end=" ", flush=True)
            # íŠ¸ë¦¬ê±° ë‹¨ì–´ë¥¼ íŒíŠ¸ë¡œ ì œê³µ (ì§§ì€ ìŒì„± ì¸ì‹ í–¥ìƒì„ ìœ„í•´)
            hints = get_hints(
                GOOGLE_SPEECH_LANGUAGE, trigger_words if USE_TRIGGER_WORD else None
            )
            if hints:
                logger.info(f"íŒíŠ¸ êµ¬ë¬¸ {len(hints)}ê°œ ì„¤ì •: {', '.join(hints[:5])}...")
            logger.info(f"Initializing for language {GOOGLE_SPEECH_LANGUAGE}...")
            client = CloudSpeechClient()
            logger.info(
                f"Google Cloud Speech-to-Text ì´ˆê¸°í™” ì™„ë£Œ (ì–¸ì–´: {GOOGLE_SPEECH_LANGUAGE})"
            )
            print("âœ… ì™„ë£Œ")

            print("ğŸ§  ë‘ë‡Œ(LLM) ì—°ê²° ì¤‘...", end=" ", flush=True)
            brain = ChipiBrain()
            print("âœ… ì™„ë£Œ")

            print("ğŸ¤ ìŒì„±(SuperTone TTS) ì—°ê²° ì¤‘...", end=" ", flush=True)
            tts = SupertonTTS()
            print("âœ… ì™„ë£Œ\n")

            # ì˜¤ë””ì˜¤ ë§¤í•‘ ë¡œë“œ
            print("ğŸ“ ì˜¤ë””ì˜¤ ë§¤í•‘ ë¡œë“œ ì¤‘...", end=" ", flush=True)
            audio_mapping = load_audio_mapping()
            if audio_mapping:
                print(f"âœ… ì™„ë£Œ ({len(audio_mapping)}ê°œ í•­ëª©)")
            else:
                print("âš ï¸ ë§¤í•‘ ì—†ìŒ")

            # Sleep/Wake ëª¨ë“œ ê´€ë¦¬
            # íŠ¸ë¦¬ê±° ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë°”ë¡œ Wake modeë¡œ ì‹œì‘
            sleep_mode = USE_TRIGGER_WORD  # íŠ¸ë¦¬ê±° ë‹¨ì–´ ì‚¬ìš© ì‹œë§Œ Sleep modeë¡œ ì‹œì‘
            last_interaction_time = None
            last_response = ""  # ì¤‘ë³µ ì‘ë‹µ ë°©ì§€ìš©

            # ì‹œì‘ ì•ˆë‚´ ìŒì„± (intro.wav íŒŒì¼ ì¬ìƒ)
            play_intro_audio(
                tts=tts, trigger_words=trigger_words, use_trigger_word=USE_TRIGGER_WORD
            )

            # ìŠ¬í”ˆ í†¤ì„ ì‚¬ìš©í•  í‚¤ì›Œë“œ ëª©ë¡ (constantsì—ì„œ ê°€ì ¸ì˜´)
            sad_keywords = SAD_TONE_KEYWORDS

            # Main loop
            while True:
                try:
                    # Sleep mode: íƒ€ì„ì•„ì›ƒ ì²´í¬
                    if not sleep_mode and last_interaction_time:
                        time_since_last = time.time() - last_interaction_time
                        if time_since_last >= SLEEP_TIMEOUT:
                            logger.info(
                                f"Wake mode íƒ€ì„ì•„ì›ƒ ({SLEEP_TIMEOUT}ì´ˆ). Sleep modeë¡œ ì „í™˜í•©ë‹ˆë‹¤."
                            )
                            sleep_mode = True
                            last_interaction_time = None

                    print("\nğŸ‘‚ ë“£ëŠ” ì¤‘...", end=" ", flush=True)
                    indicate_listening(True)

                    # Google Cloud Speech-to-Textë¡œ ìŒì„± ì¸ì‹ (VAD ë‚´ì¥)
                    user_text = client.recognize(
                        language_code=GOOGLE_SPEECH_LANGUAGE, hint_phrases=hints
                    )

                    indicate_listening(False)

                    if user_text is None:
                        print("ğŸ”• (ì¹¨ë¬µ ë˜ëŠ” ì¸ì‹ ì‹¤íŒ¨)", flush=True)
                        continue

                    user_text = user_text.strip()
                    if not user_text:
                        print("ğŸ”• (ë¹ˆ í…ìŠ¤íŠ¸)", flush=True)
                        continue

                    print(f'âœ… ì¸ì‹ë¨: "{user_text}"', flush=True)
                    logger.info(f"ì‚¬ìš©ì: {user_text}")

                    # Sleep mode: íŠ¸ë¦¬ê±° ë‹¨ì–´ í™•ì¸ (íŠ¸ë¦¬ê±° ë‹¨ì–´ê°€ í™œì„±í™”ëœ ê²½ìš°ë§Œ)
                    if sleep_mode and USE_TRIGGER_WORD:
                        if _contains_trigger_word(user_text, trigger_words):
                            logger.info("íŠ¸ë¦¬ê±° ë‹¨ì–´ ê°ì§€! Wake modeë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                            sleep_mode = False
                            last_interaction_time = time.time()
                            # íŠ¸ë¦¬ê±° ë‹¨ì–´ ì œê±° (ì˜ˆ: "ì¹˜í”¼ ì•ˆë…•í•˜ì„¸ìš”" â†’ "ì•ˆë…•í•˜ì„¸ìš”")
                            cleaned_text = user_text
                            for trigger in trigger_words:
                                cleaned_text = cleaned_text.replace(
                                    trigger, "", 1
                                ).strip()
                            if cleaned_text:
                                user_text = cleaned_text
                            else:
                                # íŠ¸ë¦¬ê±° ë‹¨ì–´ë§Œ ìˆëŠ” ê²½ìš°
                                logger.info("íŠ¸ë¦¬ê±° ë‹¨ì–´ë§Œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                                tts.speak(
                                    "ë„¤, ë§ì”€í•´ì£¼ì„¸ìš”.", language="ko", style="neutral"
                                )
                                continue
                        else:
                            continue
                    elif sleep_mode and not USE_TRIGGER_WORD:
                        # íŠ¸ë¦¬ê±° ë‹¨ì–´ê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìœ¼ë©´ ë°”ë¡œ Wake modeë¡œ ì „í™˜
                        sleep_mode = False
                        last_interaction_time = time.time()

                    # Wake mode: ìƒí˜¸ì‘ìš© ì‹œê°„ ì—…ë°ì´íŠ¸
                    if not sleep_mode:
                        last_interaction_time = time.time()

                    # ì¢…ë£Œ ëª…ë ¹ í™•ì¸
                    if any(cmd in user_text.lower() for cmd in EXIT_COMMANDS):
                        logger.info("ì¢…ë£Œ ëª…ë ¹ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                        tts.speak("ì•ˆë…•íˆ ê°€ì„¸ìš”!", language="ko", style="neutral")
                        break

                    # Sleep ëª…ë ¹ í™•ì¸ (Sleep modeë¡œ ì „í™˜)
                    if any(cmd in user_text.lower() for cmd in SLEEP_COMMANDS):
                        logger.info("Sleep modeë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                        sleep_mode = True
                        last_interaction_time = None
                        continue

                    # ì„œë³´ ëª¨í„° ì‹¤í–‰ í‚¤ì›Œë“œ ê°ì§€
                    if _contains_servo_keywords(user_text):
                        logger.info("ì„œë³´ ëª¨í„° ì‹¤í–‰ í‚¤ì›Œë“œ ê°ì§€!")
                        print("ğŸ”„ ì„œë³´ ëª¨í„° ì‹¤í–‰ ì¤‘...", flush=True)
                        # ë¹„ë™ê¸°ë¡œ ì‹¤í–‰ (ì„œë³´ ì‹¤í–‰ê³¼ ë™ì‹œì— AI ì‘ë‹µë„ ì²˜ë¦¬ ê°€ëŠ¥)
                        _run_servo_async()
                        print("âœ… ì„œë³´ ëª¨í„° ì‹¤í–‰ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)", flush=True)

                    # LED ì œì–´ í‚¤ì›Œë“œ ê°ì§€
                    led_action = _contains_led_keywords(user_text)
                    if led_action:
                        logger.info(f"LED {led_action.upper()} í‚¤ì›Œë“œ ê°ì§€!")
                        print(f"ğŸ’¡ LED {led_action.upper()} ì¤‘...", flush=True)
                        # ë¹„ë™ê¸°ë¡œ LED ì œì–´ (ë‹¤ë¥¸ ì‘ì—…ê³¼ ë™ì‹œì— ì‹¤í–‰ ê°€ëŠ¥)
                        led_state = led_action == "on"
                        threading.Thread(
                            target=lambda: _set_led_state(led_state),
                            daemon=True,
                        ).start()
                        print(
                            f"âœ… LED {led_action.upper()} ìš”ì²­ ì™„ë£Œ (ë°±ê·¸ë¼ìš´ë“œ)",
                            flush=True,
                        )

                    # ì˜¤ë””ì˜¤ ë§¤í•‘ í™•ì¸ (LLM ìš°íšŒ)
                    mapped_audio_path, mapped_response_text = find_mapped_audio(
                        user_text, audio_mapping
                    )

                    if mapped_audio_path:
                        # ë§¤í•‘ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ìˆìœ¼ë©´ LLMì„ ê±°ì¹˜ì§€ ì•Šê³  ë°”ë¡œ ì¬ìƒ
                        logger.info(f"ë§¤í•‘ëœ ì˜¤ë””ì˜¤ íŒŒì¼ ë°œê²¬: {mapped_audio_path}")
                        print(
                            f"ğŸµ ë§¤í•‘ëœ ì˜¤ë””ì˜¤ ì¬ìƒ: {os.path.basename(mapped_audio_path)}",
                            flush=True,
                        )

                        # ì‘ë‹µ í…ìŠ¤íŠ¸ ì„¤ì •
                        ai_response = mapped_response_text
                        print(f"ğŸ¤– ì¹˜í”¼: {ai_response}", flush=True)

                        # ì–¼êµ´ í‘œì • ê°ì§€ ë° ì„¤ì • (ì‘ë‹µ í…ìŠ¤íŠ¸ ê¸°ë°˜)
                        detected_emotion = _detect_face_emotion_from_response(
                            ai_response
                        )
                        print(f"ğŸ˜Š ê°ì§€ëœ í‘œì •: {detected_emotion}", flush=True)
                        if DEVICE_SERIAL:
                            threading.Thread(
                                target=lambda: _set_face_emotion(detected_emotion),
                                daemon=True,
                            ).start()

                        # TTS ì¬ìƒ ì‹œì‘ ì‹œ ì‹œê°„ ì—…ë°ì´íŠ¸
                        if not sleep_mode:
                            last_interaction_time = time.time()

                        # ì„œë³´ ëª¨í„°ì™€ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì •í™•íˆ ë™ì‹œì— ì‹œì‘
                        # ì„œë³´ ëª¨í„° ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œë¥¼ ë¯¸ë¦¬ ì°¾ê¸° (ë¸”ë¡œí‚¹ ë°©ì§€)
                        servo_script_path = _find_servo_script_path()

                        # ì„œë³´ ëª¨í„°ë¥¼ ë¨¼ì € ì‹œì‘í•˜ëŠ” í•¨ìˆ˜ (ë°”ë¡œ ì‹¤í–‰)
                        def _start_servo():
                            if servo_script_path:
                                try:
                                    process = subprocess.Popen(
                                        ["sudo", "python3", servo_script_path],
                                        stdout=subprocess.PIPE,
                                        stderr=subprocess.PIPE,
                                        text=True,
                                    )
                                    logger.debug(
                                        f"ì„œë³´ ëª¨í„° í”„ë¡œì„¸ìŠ¤ ì‹œì‘ë¨ (PID: {process.pid})"
                                    )

                                    # ì™„ë£Œ ëŒ€ê¸°ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ
                                    def _wait_servo():
                                        try:
                                            process.communicate(timeout=30)
                                            if process.returncode == 0:
                                                logger.info("ì„œë³´ ëª¨í„° ì‹¤í–‰ ì™„ë£Œ")
                                        except subprocess.TimeoutExpired:
                                            process.kill()
                                            logger.error("ì„œë³´ ëª¨í„° ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼")
                                        except Exception as e:
                                            logger.error(f"ì„œë³´ ëª¨í„° ì˜¤ë¥˜: {e}")

                                    threading.Thread(
                                        target=_wait_servo, daemon=True
                                    ).start()
                                except Exception as e:
                                    logger.error(f"ì„œë³´ ëª¨í„° ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                            else:
                                logger.error("ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                        # ì˜¤ë””ì˜¤ ì¬ìƒ í•¨ìˆ˜ (1ì´ˆ ì§€ì—°)
                        def _start_audio():
                            time.sleep(1.0)  # ì„œë³´ ëª¨í„° ì‹œì‘ ì‹œê°„ í™•ë³´ë¥¼ ìœ„í•´ 1ì´ˆ ëŒ€ê¸°
                            play_audio_file_by_path(mapped_audio_path)

                        # ì„œë³´ ëª¨í„°ë¥¼ ë¨¼ì € ì‹œì‘ (ë³„ë„ ìŠ¤ë ˆë“œ)
                        servo_thread = threading.Thread(
                            target=_start_servo, daemon=True
                        )
                        servo_thread.start()

                        # ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ (1ì´ˆ ì§€ì—° í›„ ì¬ìƒ)
                        audio_thread = threading.Thread(
                            target=_start_audio, daemon=True
                        )
                        audio_thread.start()

                        logger.info(
                            f"ì„œë³´ ëª¨í„°ì™€ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë™ì‹œì— ì‹œì‘: {mapped_audio_path}"
                        )

                        # TTS ì¬ìƒ ì™„ë£Œ í›„ ì‹œê°„ ì—…ë°ì´íŠ¸
                        if not sleep_mode:
                            last_response = ai_response
                            last_interaction_time = time.time()

                        continue  # LLM í˜¸ì¶œ ì—†ì´ ë‹¤ìŒ ë£¨í”„ë¡œ (LED ì œì–´ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì‹¤í–‰ë¨)

                    # ìŠ¬í”ˆ í†¤ í‚¤ì›Œë“œ ê°ì§€
                    is_sad_topic = any(keyword in user_text for keyword in sad_keywords)
                    print(f"ğŸ” ìŠ¬í”ˆ í† í”½ ê°ì§€: {is_sad_topic}", flush=True)

                    # AI ì‘ë‹µ ìƒì„± (LLM í˜¸ì¶œ)
                    print("ğŸ§  ìƒê°í•˜ëŠ” ì¤‘...", end=" ", flush=True)
                    brain.add_msg(user_text)
                    ai_response = brain.wait_run(
                        ai_name="chipi", device_serial=device_serial
                    )
                    print("âœ… ì™„ë£Œ", flush=True)
                    logger.info(f"AI: {ai_response}")

                    if not ai_response:
                        response_style = "sad" if is_sad_topic else "neutral"
                        pitch_shift = -10 if is_sad_topic else 0
                        tts.speak(
                            "ë¯¸ì•ˆ, ë‹¤ì‹œ ë§í•´ì¤„ë˜?",
                            language="ko",
                            style=response_style,
                            pitch_shift=pitch_shift,
                        )
                        continue

                    # ì¤‘ë³µ ì‘ë‹µ ë°©ì§€
                    if ai_response == last_response:
                        continue

                    # ë‹µë³€ ì¶œë ¥ ë° ìŒì„± ì¬ìƒ
                    print(f"ğŸ¤– ì¹˜í”¼: {ai_response}")

                    # TTS ì¬ìƒ ì‹œì‘ ì‹œ ì‹œê°„ ì—…ë°ì´íŠ¸
                    if not sleep_mode:
                        last_interaction_time = time.time()

                    # ì–¼êµ´ í‘œì • ê°ì§€ ë° ì„¤ì • (í‚¤ì›Œë“œ ê¸°ë°˜)
                    detected_emotion = _detect_face_emotion_from_response(ai_response)
                    print(f"ğŸ˜Š ê°ì§€ëœ í‘œì •: {detected_emotion}", flush=True)
                    # ë¹„ë™ê¸°ë¡œ ì–¼êµ´ í‘œì • ì„¤ì • (TTSì™€ ë™ì‹œì— ì‹¤í–‰)
                    if DEVICE_SERIAL:
                        threading.Thread(
                            target=lambda: _set_face_emotion(detected_emotion),
                            daemon=True,
                        ).start()

                    # ìŠ¬í”ˆ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìŠ¬í”ˆ í†¤ìœ¼ë¡œ, ì—†ìœ¼ë©´ ì¤‘ë¦½ í†¤ìœ¼ë¡œ ì¬ìƒ
                    response_style = "sad" if is_sad_topic else "neutral"
                    pitch_shift = -10 if is_sad_topic else 0
                    print(
                        f"ğŸ¤ ì‘ë‹µ í†¤: {response_style}, í”¼ì¹˜: {pitch_shift}", flush=True
                    )

                    # TTS ì¬ìƒê³¼ ë™ì‹œì— ì„œë³´ ëª¨í„° ì‹¤í–‰ (ë¹„ë™ê¸°)
                    _run_servo_async()

                    tts.speak(
                        ai_response,
                        language="ko",
                        style=response_style,
                        pitch_shift=pitch_shift,
                    )

                    # TTS ì¬ìƒ ì™„ë£Œ í›„ ì‹œê°„ ì—…ë°ì´íŠ¸
                    if not sleep_mode:
                        last_response = ai_response
                        last_interaction_time = time.time()

                except KeyboardInterrupt:
                    logger.info("\nì‚¬ìš©ìì— ì˜í•´ ì¢…ë£Œë¨")
                    break
                except Exception as e:
                    logger.error(f"ë£¨í”„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", exc_info=True)
                    print(f"\nâš ï¸ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    time.sleep(1)  # ì˜¤ë¥˜ í›„ ì ì‹œ ëŒ€ê¸°

    except KeyboardInterrupt:
        logger.info("\nì‚¬ìš©ìì— ì˜í•´ ì¢…ë£Œë¨")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
        input("ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„°...")
    finally:
        # Board ì •ë¦¬
        if board:
            try:
                board.close()
            except Exception:
                pass


if __name__ == "__main__":
    main()
