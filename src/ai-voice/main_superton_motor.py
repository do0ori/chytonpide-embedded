#!/usr/bin/env python3
"""
SuperTone TTS + Azure Speech REST API STT ìŒì„± ì–´ì‹œìŠ¤í„´íŠ¸
ë¼ì¦ˆë² ë¦¬íŒŒì´ ì œë¡œ WH (Python 3.7.3) í˜¸í™˜

Azure Speech SDK ëŒ€ì‹  REST APIë¥¼ ì‚¬ìš©í•˜ì—¬ Raspberry Pi Zero (ARMv6) í˜¸í™˜ì„± í™•ë³´
AIY Projects ëª¨ë“ˆ(aiy.voice.audio)ì„ ì‚¬ìš©í•˜ì—¬ ë§ˆì´í¬ì™€ ìŠ¤í”¼ì»¤ ì œì–´
"""

import io
import logging
import os
import subprocess
import sys
import tempfile
import threading
import time

# í•œê¸€ ì¶œë ¥ ê¹¨ì§ ë°©ì§€ (Python 3.7.3 í˜¸í™˜)
if hasattr(sys.stdout, "reconfigure"):
    try:
        sys.stdout.reconfigure(encoding="utf-8")
    except (AttributeError, ValueError):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")
else:
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")

# ê²½ë¡œ ì„¤ì • (servo íŒ¨í‚¤ì§€ì²˜ëŸ¼)
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
if current_dir not in sys.path:
    sys.path.insert(0, current_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

try:
    from dotenv import load_dotenv
except ImportError:
    print("python-dotenvê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip3 install python-dotenv")
    sys.exit(1)

try:
    import requests

    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False
    print("requestsê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: pip3 install requests")
    sys.exit(1)

# AIY Projects ëª¨ë“ˆ (ì‹œìŠ¤í…œì— ì´ë¯¸ ì„¤ì¹˜ëœ ê²ƒ ì‚¬ìš©)
try:
    from aiy.voice.audio import AudioFormat, Recorder, play_wav

    HAS_AIY_AUDIO = True
except ImportError:
    HAS_AIY_AUDIO = False
    print("ê²½ê³ : AIY Projects audio ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

try:
    from aiy.board import Board, Led

    HAS_BOARD = True
except ImportError:
    HAS_BOARD = False

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ============================================================================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
# ============================================================================

# .env íŒŒì¼ ê²½ë¡œ ì°¾ê¸°
current_dir = os.path.dirname(os.path.abspath(__file__))
config_path = os.path.join(current_dir, "config", ".env")
if os.path.exists(config_path):
    load_dotenv(config_path)
else:
    # ìƒìœ„ ë””ë ‰í† ë¦¬ì—ì„œ ì°¾ê¸°
    parent_config = os.path.join(os.path.dirname(current_dir), "config", ".env")
    if os.path.exists(parent_config):
        load_dotenv(parent_config)
    else:
        # ê¸°ë³¸ ê²½ë¡œ
        load_dotenv()

# Azure Speech ì„¤ì • (STTìš©)
AZURE_SPEECH_API_KEY = os.environ.get("AZURE_SPEECH_API_KEY")
AZURE_SPEECH_REGION = os.environ.get("AZURE_SPEECH_REGION")
AZURE_SPEECH_ENDPOINT = os.environ.get("AZURE_SPEECH_ENDPOINT")

# SuperTone ì„¤ì • (TTSìš©)
SUPERTON_API_KEY = os.environ.get("SUPERTON_API_KEY")
SUPERTON_VOICE_ID = os.environ.get("SUPERTON_VOICE_ID")

# íŠ¸ë¦¬ê±° ë‹¨ì–´ ì„¤ì • (Wake word)
TRIGGER_WORDS = os.environ.get("TRIGGER_WORDS", "ì¹˜í”¼")

# Sleep mode íƒ€ì„ì•„ì›ƒ ì„¤ì •
SLEEP_TIMEOUT = float(os.environ.get("SLEEP_TIMEOUT", "10.0"))

# VAD ì„¤ì • (ì‹œë„ëŸ¬ìš´ í™˜ê²½ ëŒ€ì‘)
VAD_ENERGY_THRESHOLD = float(os.environ.get("VAD_ENERGY_THRESHOLD", "0.005"))
VAD_SILENCE_DURATION = float(os.environ.get("VAD_SILENCE_DURATION", "0.8"))
VAD_MIN_SPEECH_DURATION = float(os.environ.get("VAD_MIN_SPEECH_DURATION", "0.3"))

# ê²€ì¦
if not AZURE_SPEECH_API_KEY or not AZURE_SPEECH_REGION:
    logger.error(
        "AZURE_SPEECH_API_KEYì™€ AZURE_SPEECH_REGIONì´ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
    )
    sys.exit(1)

if not SUPERTON_API_KEY or not SUPERTON_VOICE_ID:
    logger.error(
        "SUPERTON_API_KEYì™€ SUPERTON_VOICE_IDê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
    )
    sys.exit(1)

# Azure Speech REST API ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
# ì°¸ê³ : ìµœì‹  í˜•ì‹ì€ https://{region}.stt.speech.microsoft.com
# êµ¬ë²„ì „ í˜•ì‹ì€ ìë™ìœ¼ë¡œ ìƒˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ë©ë‹ˆë‹¤.
if AZURE_SPEECH_ENDPOINT:
    AZURE_SPEECH_ENDPOINT = AZURE_SPEECH_ENDPOINT.rstrip("/")
    # êµ¬ë²„ì „ í˜•ì‹ ê°ì§€ (.api.cognitive.microsoft.com ë˜ëŠ” .cognitiveservices.azure.com)
    if (
        ".api.cognitive.microsoft.com" in AZURE_SPEECH_ENDPOINT
        or ".cognitiveservices.azure.com" in AZURE_SPEECH_ENDPOINT
    ):
        logger.info("êµ¬ë²„ì „ ì—”ë“œí¬ì¸íŠ¸ ê°ì§€, ìƒˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.")
        logger.info(f"ì›ë³¸: {AZURE_SPEECH_ENDPOINT}")
        # Region ê¸°ë°˜ìœ¼ë¡œ ìƒˆ ì—”ë“œí¬ì¸íŠ¸ ìƒì„±
        AZURE_SPEECH_ENDPOINT = (
            f"https://{AZURE_SPEECH_REGION}.stt.speech.microsoft.com"
        )
        logger.info(f"ë³€í™˜ë¨: {AZURE_SPEECH_ENDPOINT}")
else:
    # ê¸°ë³¸ STT ì—”ë“œí¬ì¸íŠ¸ í˜•ì‹ (ê¶Œì¥)
    AZURE_SPEECH_ENDPOINT = f"https://{AZURE_SPEECH_REGION}.stt.speech.microsoft.com"

logger.info(f"STT ì—”ë“œí¬ì¸íŠ¸: {AZURE_SPEECH_ENDPOINT}")

# ============================================================================
# Azure Speech REST API STT
# ============================================================================


class AzureSpeechRESTSTT:
    """Azure Speech Service REST APIë¥¼ ì‚¬ìš©í•œ ìŒì„± ì¸ì‹ (STT)"""

    def __init__(self, language="ko-KR"):
        """
        Args:
            language: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸ê°’: ko-KR)
        """
        self.language = language
        self.api_key = AZURE_SPEECH_API_KEY
        self.stt_url = f"{AZURE_SPEECH_ENDPOINT}/speech/recognition/conversation/cognitiveservices/v1"
        logger.info(f"Azure Speech REST API STT ì´ˆê¸°í™” ì™„ë£Œ (ì–¸ì–´: {language})")

    def recognize_from_file(self, audio_file_path):
        """
        ì˜¤ë””ì˜¤ íŒŒì¼ë¡œë¶€í„° ìŒì„±ì„ ì¸ì‹í•©ë‹ˆë‹¤.

        Args:
            audio_file_path: WAV íŒŒì¼ ê²½ë¡œ

        Returns:
            ì¸ì‹ëœ í…ìŠ¤íŠ¸ ë˜ëŠ” None
        """
        try:
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
            with open(audio_file_path, "rb") as audio_file:
                audio_data = audio_file.read()

            # í—¤ë” ì„¤ì •
            headers = {
                "Ocp-Apim-Subscription-Key": self.api_key,
                "Content-Type": "audio/wav; codecs=audio/pcm; samplerate=16000; channels=1",
                "Accept": "application/json",
            }

            # íŒŒë¼ë¯¸í„° (languageëŠ” í•„ìˆ˜)
            params = {"language": self.language}

            # ìš”ì²­
            logger.info("ìŒì„± ì¸ì‹ ì¤‘...")
            response = requests.post(
                self.stt_url,
                headers=headers,
                params=params,
                data=audio_data,
                timeout=15,
            )

            if response.status_code == 200:
                result = response.json()
                logger.debug(f"STT ì‘ë‹µ: {result}")

                # ì‘ë‹µ í˜•ì‹ í™•ì¸
                if "RecognitionStatus" in result:
                    if result["RecognitionStatus"] == "Success":
                        # DisplayTextì™€ Text ëª¨ë‘ í™•ì¸
                        text = result.get("DisplayText", "") or result.get("Text", "")
                        text = text.strip()
                        if text:
                            logger.info(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")
                            return text
                        else:
                            logger.warning("ì¸ì‹ì€ ì„±ê³µí–ˆì§€ë§Œ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
                            logger.debug(f"ì „ì²´ ì‘ë‹µ: {result}")
                            # ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸° í™•ì¸
                            try:
                                file_size = os.path.getsize(audio_file_path)
                                logger.debug(f"ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸°: {file_size} bytes")
                            except Exception:
                                pass
                            return None
                    else:
                        status = result.get("RecognitionStatus", "Unknown")
                        error_details = result.get("ErrorDetails", "")
                        logger.warning(f"ì¸ì‹ ì‹¤íŒ¨: {status} - {error_details}")
                        return None
                elif "DisplayText" in result:
                    # ì§ì ‘ DisplayTextê°€ ìˆëŠ” ê²½ìš°
                    text = result["DisplayText"].strip()
                    logger.info(f"ì¸ì‹ëœ í…ìŠ¤íŠ¸: {text}")
                    return text
                else:
                    logger.warning(f"ì˜ˆìƒì¹˜ ëª»í•œ ì‘ë‹µ í˜•ì‹: {result}")
                    return None
            elif response.status_code == 401:
                logger.error("STT API ì¸ì¦ ì˜¤ë¥˜ (401): API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
                logger.error(f"ì‘ë‹µ: {response.text}")
                return None
            elif response.status_code == 404:
                logger.error("STT API ì—”ë“œí¬ì¸íŠ¸ ì˜¤ë¥˜ (404): URLì„ í™•ì¸í•˜ì„¸ìš”.")
                logger.error(f"ì‚¬ìš©ëœ URL: {self.stt_url}")
                logger.error(f"Region: {AZURE_SPEECH_REGION}")
                logger.error(f"ì‘ë‹µ: {response.text}")
                return None
            else:
                logger.error(f"STT API ì˜¤ë¥˜ ({response.status_code}): {response.text}")
                return None

        except Exception as e:
            logger.error(f"STT ì˜¤ë¥˜: {e}", exc_info=True)
            return None


# ============================================================================
# SuperTone TTS (REST API)
# ============================================================================


class SupertonTTS:
    """SuperTone APIë¥¼ ì‚¬ìš©í•œ TTS í´ë˜ìŠ¤ (AIY Projects play_wav ì‚¬ìš©)"""

    def __init__(self, voice_id=None, api_key=None):
        """
        ì´ˆê¸°í™”

        Args:
            voice_id: ìŒì„± ID (ê¸°ë³¸ê°’: envì˜ SUPERTON_VOICE_ID)
            api_key: API í‚¤ (ê¸°ë³¸ê°’: envì˜ SUPERTON_API_KEY)
        """
        self.api_key = api_key or SUPERTON_API_KEY
        self.voice_id = voice_id or SUPERTON_VOICE_ID

        if not self.api_key:
            raise ValueError("âŒ SUPERTON_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        logger.info("SuperTone TTS ì´ˆê¸°í™” ì™„ë£Œ (ìŒì„± ID: %s)", self.voice_id)

    def generate(
        self,
        text,
        language="ko",
        style="neutral",
        output_format="wav",
        pitch_shift=0,
        speed=1,
        pitch_variance=1,
    ):
        """
        SuperTone APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ìƒì„±

        Args:
            text: í…ìŠ¤íŠ¸
            language: ì–¸ì–´ (ê¸°ë³¸ê°’: "ko")
            style: ìŠ¤íƒ€ì¼ (ê¸°ë³¸ê°’: "neutral")
            output_format: ì¶œë ¥ í˜•ì‹ - "wav" ë˜ëŠ” "mp3" (ê¸°ë³¸ê°’: "wav")
            pitch_shift: ìŒë†’ì´ ì¡°ì • (-20 ~ 20, ê¸°ë³¸ê°’: 0)
            speed: ì¬ìƒ ì†ë„ (0.5 ~ 2, ê¸°ë³¸ê°’: 1)
            pitch_variance: ìŒë†’ì´ ë³€ë™ì„± (0 ~ 2, ê¸°ë³¸ê°’: 1)

        Returns:
            ìŒì„± ë°”ì´íŠ¸ ë°ì´í„° ë˜ëŠ” None
        """
        url = f"https://supertoneapi.com/v1/text-to-speech/{self.voice_id}"

        headers = {"x-sup-api-key": self.api_key, "Content-Type": "application/json"}

        payload = {
            "text": text,
            "language": language,
            "style": style,
            "model": "sona_speech_1",
            "output_format": output_format,
            "voice_settings": {
                "pitch_shift": pitch_shift,
                "pitch_variance": pitch_variance,
                "speed": speed,
            },
        }

        try:
            logger.debug(f"SuperTone ìŒì„± ìƒì„± ì¤‘: {text[:20]}...")
            response = requests.post(url, json=payload, headers=headers, timeout=30)

            if response.status_code == 200:
                logger.debug("SuperTone ìŒì„± ìƒì„± ì™„ë£Œ")
                return response.content
            else:
                logger.error(
                    f"SuperTone API ì˜¤ë¥˜ (ìƒíƒœ: {response.status_code}): {response.text}"
                )
                return None

        except requests.exceptions.Timeout:
            logger.error("SuperTone ìš”ì²­ ì‹œê°„ ì´ˆê³¼ (30ì´ˆ)")
            return None
        except Exception as e:
            logger.error(f"SuperTone ì˜¤ë¥˜: {e}", exc_info=True)
            return None

    def speak(
        self,
        text,
        language="ko",
        style="neutral",
        pitch_shift=0,
        speed=1,
        pitch_variance=1,
    ):
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¬ìƒ (AIY Projects play_wav ì‚¬ìš©)

        Args:
            text: ë§í•  í…ìŠ¤íŠ¸
            language: ì–¸ì–´ (ê¸°ë³¸ê°’: "ko")
            style: ìŠ¤íƒ€ì¼ (ê¸°ë³¸ê°’: "neutral")
            pitch_shift: ìŒë†’ì´ ì¡°ì • (-20 ~ 20, ê¸°ë³¸ê°’: 0)
            speed: ì¬ìƒ ì†ë„ (0.5 ~ 2, ê¸°ë³¸ê°’: 1)
            pitch_variance: ìŒë†’ì´ ë³€ë™ì„± (0 ~ 2, ê¸°ë³¸ê°’: 1)
        """
        audio_data = self.generate(
            text,
            language,
            style,
            output_format="wav",
            pitch_shift=pitch_shift,
            speed=speed,
            pitch_variance=pitch_variance,
        )

        if audio_data:
            try:
                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                with tempfile.NamedTemporaryFile(
                    suffix=".wav", delete=False
                ) as tmp_file:
                    tmp_file.write(audio_data)
                    tmp_file_path = tmp_file.name

                try:
                    # ì¬ìƒ (AIY Projects play_wav ì‚¬ìš©)
                    if HAS_AIY_AUDIO:
                        play_wav(tmp_file_path)
                    else:
                        subprocess.run(["aplay", "-q", tmp_file_path], check=True)

                    logger.debug("SuperTone ìŒì„± ì¶œë ¥ ì™„ë£Œ")
                finally:
                    try:
                        os.unlink(tmp_file_path)
                    except Exception:
                        pass

            except Exception as e:
                logger.error(f"SuperTone ì¬ìƒ ì˜¤ë¥˜: {e}", exc_info=True)


# ============================================================================
# VAD (Voice Activity Detection) - ê°„ë‹¨í•œ ì—ë„ˆì§€ ê¸°ë°˜
# ============================================================================

# ê¸°ë³¸ ì˜¤ë””ì˜¤ í¬ë§·
if HAS_AIY_AUDIO:
    DEFAULT_AUDIO_FORMAT = AudioFormat(
        sample_rate_hz=16000, num_channels=1, bytes_per_sample=2
    )
else:
    DEFAULT_AUDIO_FORMAT = None


def calculate_rms(audio_data):
    """ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ RMS ì—ë„ˆì§€ ê³„ì‚°"""
    if not audio_data:
        return 0.0

    import array

    samples = array.array("h", audio_data)
    if len(samples) == 0:
        return 0.0

    # RMS ê³„ì‚°
    sum_squares = sum(float(s) ** 2 for s in samples)
    mean_square = sum_squares / len(samples)
    rms = mean_square**0.5
    # ì •ê·œí™” (16-bit: ìµœëŒ€ê°’ 32768)
    normalized = min(rms / 32768.0, 1.0)
    return normalized


class EnergyBasedVAD:
    """ì—ë„ˆì§€ ê¸°ë°˜ Voice Activity Detection"""

    def __init__(
        self,
        energy_threshold=0.01,
        silence_duration=1.0,
        min_speech_duration=0.3,
        chunk_duration=0.1,
    ):
        self.energy_threshold = energy_threshold
        self.silence_duration = silence_duration
        self.min_speech_duration = min_speech_duration
        self.chunk_duration = chunk_duration

    def record(self, on_start=None, on_stop=None, filename=None):
        """
        ìŒì„±ì„ ê°ì§€í•˜ê³  ë…¹ìŒí•©ë‹ˆë‹¤.

        Returns:
            ì˜¤ë””ì˜¤ ë°ì´í„° (bytes) ë˜ëŠ” None
        """
        if not HAS_AIY_AUDIO:
            logger.error("AIY Projects audio ëª¨ë“ˆì´ í•„ìš”í•©ë‹ˆë‹¤.")
            return None

        silence_chunks = 0
        speech_chunks = 0
        speech_started = False

        silence_chunks_threshold = int(self.silence_duration / self.chunk_duration)
        min_speech_chunks = int(self.min_speech_duration / self.chunk_duration)

        logger.info("VAD ëŒ€ê¸° ì¤‘...")

        audio_chunks = []

        with Recorder() as recorder:
            chunks = recorder.record(
                DEFAULT_AUDIO_FORMAT,
                chunk_duration_sec=self.chunk_duration,
                on_start=lambda: None,
                on_stop=lambda: None,
                filename=filename,
            )

            for chunk in chunks:
                energy = calculate_rms(chunk)

                if not speech_started:
                    if energy > self.energy_threshold:
                        speech_started = True
                        speech_chunks = 1
                        audio_chunks.append(chunk)
                        if on_start:
                            on_start()
                        logger.info("ìŒì„± ê°ì§€ë¨")
                else:
                    audio_chunks.append(chunk)
                    if energy > self.energy_threshold:
                        speech_chunks += 1
                        silence_chunks = 0
                    else:
                        silence_chunks += 1
                        # ì¶©ë¶„í•œ ì¹¨ë¬µì´ ê°ì§€ë˜ë©´ ì¦‰ì‹œ ì¢…ë£Œ
                        if silence_chunks >= silence_chunks_threshold:
                            if speech_chunks >= min_speech_chunks:
                                recorder.done()
                                if recorder._process:
                                    recorder._process.terminate()
                                    time.sleep(0.05)
                                if on_stop:
                                    on_stop()
                                logger.info("ìŒì„± ì¢…ë£Œ ê°ì§€ë¨")
                                break
                            else:
                                # ë„ˆë¬´ ì§§ì€ ìŒì„±, ì¬ì‹œì‘
                                speech_started = False
                                speech_chunks = 0
                                silence_chunks = 0
                                audio_chunks = []

        if audio_chunks and speech_chunks >= min_speech_chunks:
            # ì˜¤ë””ì˜¤ ë°ì´í„° í•©ì¹˜ê¸°
            import array

            combined = array.array("h")
            for chunk in audio_chunks:
                combined.extend(array.array("h", chunk))

            # WAV íŒŒì¼ë¡œ ë³€í™˜ (íŒŒì¼ëª…ì´ ì œê³µëœ ê²½ìš°ì—ë§Œ)
            if filename:
                import wave

                try:
                    with wave.open(filename, "wb") as wav_file:
                        wav_file.setnchannels(DEFAULT_AUDIO_FORMAT.num_channels)
                        wav_file.setsampwidth(DEFAULT_AUDIO_FORMAT.bytes_per_sample)
                        wav_file.setframerate(DEFAULT_AUDIO_FORMAT.sample_rate_hz)
                        wav_file.writeframes(combined.tobytes())
                    logger.debug(f"ì˜¤ë””ì˜¤ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {filename}")
                except Exception as e:
                    logger.warning(f"íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")

            return combined.tobytes()

        return None


# ============================================================================
# ë©”ì¸ í•¨ìˆ˜
# ============================================================================

# ìƒëŒ€ ê²½ë¡œë¡œ import ì‹œë„ (í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€)
try:
    from core.chipi_brain import ChipiBrain
except ImportError:
    # ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì‹œë„
    try:
        current_dir = os.path.dirname(os.path.abspath(__file__))
        parent_dir = os.path.dirname(current_dir)
        if parent_dir not in sys.path:
            sys.path.insert(0, parent_dir)
        from core.chipi_brain import ChipiBrain
    except ImportError:
        # ìµœìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ì‹œë„
        try:
            current_dir = os.path.dirname(os.path.abspath(__file__))
            parent_dir = os.path.dirname(os.path.dirname(current_dir))
            if parent_dir not in sys.path:
                sys.path.insert(0, parent_dir)
            from core.chipi_brain import ChipiBrain
        except ImportError as e:
            print(f"âŒ ChipiBrainì„ importí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            sys.exit(1)


def _contains_trigger_word(text, trigger_words):
    """í…ìŠ¤íŠ¸ì— íŠ¸ë¦¬ê±° ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸"""
    if not text or not trigger_words:
        return False
    text_lower = text.lower()
    return any(trigger in text_lower for trigger in trigger_words)


def _find_servo_script_path():
    """ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ì°¾ê¸°"""
    # í˜„ì¬ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì°¾ê¸°
    main_file_dir = os.path.dirname(os.path.abspath(__file__))
    main_file_parent = os.path.dirname(main_file_dir)

    # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ê²½ë¡œ ì‹œë„
    possible_paths = [
        # í˜„ì¬ ë””ë ‰í† ë¦¬ ê¸°ì¤€ (src/ai-voice/servo/examples/plant_shaker.py)
        os.path.join(main_file_dir, "servo", "examples", "plant_shaker.py"),
        # ìƒìœ„ ë””ë ‰í† ë¦¬ ê¸°ì¤€
        os.path.join(main_file_parent, "servo", "examples", "plant_shaker.py"),
        # í™ˆ ë””ë ‰í† ë¦¬ ê¸°ì¤€ (~/chytonpide/servo/examples/plant_shaker.py)
        os.path.expanduser("~/chytonpide/servo/examples/plant_shaker.py"),
        # ì ˆëŒ€ ê²½ë¡œ (ë¼ì¦ˆë² ë¦¬íŒŒì´ ê¸°ë³¸ ê²½ë¡œ)
        "/home/pi/chytonpide/servo/examples/plant_shaker.py",
    ]

    for path in possible_paths:
        abs_path = os.path.abspath(os.path.expanduser(path))
        if os.path.exists(abs_path):
            logger.info(f"ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ ì°¾ìŒ: {abs_path}")
            return abs_path

    logger.warning("ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ê²½ë¡œ:")
    for path in possible_paths:
        logger.warning(f"  - {os.path.abspath(os.path.expanduser(path))}")
    return None


def _run_servo_plant_shake():
    """ì„œë³´ ëª¨í„°ë¡œ í™”ë¶„ í”ë“¤ê¸° ì‹¤í–‰ (subprocess ì‚¬ìš©)"""
    script_path = _find_servo_script_path()
    if not script_path:
        logger.error("ì„œë³´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    try:
        logger.info(f"ì„œë³´ ëª¨í„° ì‹¤í–‰: {script_path}")
        # sudo ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰
        result = subprocess.run(
            ["sudo", "python3", script_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            timeout=30,  # ìµœëŒ€ 30ì´ˆ ëŒ€ê¸°
            text=True,
        )

        if result.returncode == 0:
            logger.info("ì„œë³´ ëª¨í„° ì‹¤í–‰ ì™„ë£Œ")
            if result.stdout:
                logger.debug(f"ì„œë³´ ì¶œë ¥: {result.stdout}")
            return True
        else:
            logger.error(f"ì„œë³´ ëª¨í„° ì‹¤í–‰ ì‹¤íŒ¨ (ì½”ë“œ: {result.returncode})")
            if result.stderr:
                logger.error(f"ì„œë³´ ì˜¤ë¥˜: {result.stderr}")
            return False

    except subprocess.TimeoutExpired:
        logger.error("ì„œë³´ ëª¨í„° ì‹¤í–‰ ì‹œê°„ ì´ˆê³¼ (30ì´ˆ)")
        return False
    except Exception as e:
        logger.error(f"ì„œë³´ ëª¨í„° ì‹¤í–‰ ì˜¤ë¥˜: {e}", exc_info=True)
        return False


def _run_servo_async():
    """ì„œë³´ ëª¨í„°ë¥¼ ë¹„ë™ê¸°ë¡œ ì‹¤í–‰ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)"""

    def _servo_worker():
        try:
            _run_servo_plant_shake()
        except Exception as e:
            logger.error(f"ì„œë³´ ëª¨í„° ë¹„ë™ê¸° ì‹¤í–‰ ì˜¤ë¥˜: {e}")

    thread = threading.Thread(target=_servo_worker, daemon=True)
    thread.start()
    logger.info("ì„œë³´ ëª¨í„° ë¹„ë™ê¸° ì‹¤í–‰ ì‹œì‘")
    return thread


def _contains_servo_keywords(text):
    """ì„œë³´ ëª¨í„° ì‹¤í–‰ í‚¤ì›Œë“œ ê°ì§€"""
    if not text:
        return False

    servo_keywords = [
        "í™”ë¶„ í”ë“¤ì–´",
        "í™”ë¶„ í”ë“¤ì–´ì¤˜",
        "ëª¨í„° ì›€ì§ì—¬",
        "ì„œë³´ ì›€ì§ì—¬",
        "í”ë“¤ì–´ì¤˜",
        "í”ë“¤ì–´",
        "ëª¨í„° ì‹¤í–‰",
        "ì„œë³´ ì‹¤í–‰",
    ]

    text_lower = text.lower()
    return any(keyword in text_lower for keyword in servo_keywords)


def main():
    device_serial = os.environ.get("DEVICE_SERIAL")
    if not device_serial:
        print("âš ï¸ DEVICE_SERIAL ì—†ìŒ")

    # íŠ¸ë¦¬ê±° ë‹¨ì–´ ì²˜ë¦¬
    trigger_words_str = TRIGGER_WORDS.strip()
    if "," in trigger_words_str:
        trigger_words = [w.strip().lower() for w in trigger_words_str.split(",")]
    elif " " in trigger_words_str:
        trigger_words = [w.strip().lower() for w in trigger_words_str.split()]
    else:
        trigger_words = [trigger_words_str.lower()]

    # ë¹ˆ ë‹¨ì–´ ì œê±°
    trigger_words = [w for w in trigger_words if w]
    if not trigger_words:
        trigger_words = ["ì¹˜í”¼"]

    print("\n============== âš¡ ì¹˜í”¼(Chipi) SuperTone TTS ëª¨ë“œ ì‹œì‘ ==============\n")
    print(f"íŠ¸ë¦¬ê±° ë‹¨ì–´: {', '.join(trigger_words)}")
    print(f"Sleep timeout: {SLEEP_TIMEOUT}ì´ˆ")
    print("Sleep modeì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤. íŠ¸ë¦¬ê±° ë‹¨ì–´ë¥¼ ë§í•˜ë©´ Wake modeë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
    print("Wake modeì—ì„œëŠ” íŠ¸ë¦¬ê±° ë‹¨ì–´ ì—†ì´ ëª¨ë“  ë§ì— ì‘ë‹µí•©ë‹ˆë‹¤.")
    print("ì¼ì • ì‹œê°„ ë™ì•ˆ ë§ì´ ì—†ìœ¼ë©´ ìë™ìœ¼ë¡œ Sleep modeë¡œ ì „í™˜ë©ë‹ˆë‹¤.")
    print("ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ'ë¼ê³  ë§í•˜ê±°ë‚˜ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”.\n")

    # Board (LED) ì´ˆê¸°í™”
    board = None
    if HAS_BOARD:
        try:
            board = Board()
            logger.info("Board ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            logger.warning(f"Board ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

    def indicate_listening(is_listening):
        """ë“£ëŠ” ì¤‘ ìƒíƒœë¥¼ LEDë¡œ í‘œì‹œ"""
        if board and board.led:
            if is_listening:
                board.led.state = Led.ON
            else:
                board.led.state = Led.OFF

    try:
        print("ğŸ§  ë‘ë‡Œ(LLM) ì—°ê²° ì¤‘...", end=" ", flush=True)
        brain = ChipiBrain()
        print("âœ… ì™„ë£Œ")

        print("ğŸ¤ ìŒì„±(SuperTone TTS) ì—°ê²° ì¤‘...", end=" ", flush=True)
        tts = SupertonTTS()
        print("âœ… ì™„ë£Œ")

        print("ğŸ‘‚ ìŒì„± ì¸ì‹(STT) ì—°ê²° ì¤‘...", end=" ", flush=True)
        stt = AzureSpeechRESTSTT(language="ko-KR")
        print("âœ… ì™„ë£Œ\n")

        # VAD ì´ˆê¸°í™” (í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì • ê°€ëŠ¥, ì‹œë„ëŸ¬ìš´ í™˜ê²½ ëŒ€ì‘)
        # ì‹œë„ëŸ¬ìš´ í™˜ê²½ì—ì„œëŠ” í™˜ê²½ ë³€ìˆ˜ë¡œ ì¡°ì •:
        # VAD_ENERGY_THRESHOLD=0.02 (ë°°ê²½ ì†ŒìŒ ë¬´ì‹œ)
        # VAD_SILENCE_DURATION=1.2 (ë§ ëê¹Œì§€ ë” ê¸°ë‹¤ë¦¼)
        # VAD_MIN_SPEECH_DURATION=0.5 (ë” ê¸´ ìŒì„±ë§Œ ì¸ì‹)
        vad = EnergyBasedVAD(
            energy_threshold=VAD_ENERGY_THRESHOLD,
            silence_duration=VAD_SILENCE_DURATION,
            min_speech_duration=VAD_MIN_SPEECH_DURATION,
        )
        logger.info(
            f"VAD ì„¤ì •: energy_threshold={VAD_ENERGY_THRESHOLD}, "
            f"silence_duration={VAD_SILENCE_DURATION}, "
            f"min_speech_duration={VAD_MIN_SPEECH_DURATION}"
        )

        # Sleep/Wake ëª¨ë“œ ê´€ë¦¬
        sleep_mode = True  # ì´ˆê¸° ìƒíƒœ: Sleep mode
        last_interaction_time = None
        last_response = ""  # ì¤‘ë³µ ì‘ë‹µ ë°©ì§€ìš©

        # ì‹œì‘ ì•ˆë‚´ ìŒì„± (Sleep mode)
        main_trigger = trigger_words[0] if trigger_words else "ì¹˜í”¼"
        tts.speak(
            f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {main_trigger}ì…ë‹ˆë‹¤. ëŒ€í™”í•˜ê³  ì‹¶ì„ ë•Œ ì €ë¥¼ ë¶ˆëŸ¬ì£¼ì„¸ìš”.",
            f"ì•ˆë…•í•˜ì„¸ìš”! ì €ëŠ” {main_trigger}ì…ë‹ˆë‹¤. íŠ¸ë¦¬ê±° ë‹¨ì–´ë¥¼ ë§ì”€í•´ì£¼ì„¸ìš”.",
            language="ko",
            style="neutral",
        )

        # í”„ë¡œê·¸ë¨ ì‹œì‘ ì‹œ ì„œë³´ ëª¨í„° í•œ ë²ˆ ì‹¤í–‰ (TTSì™€ ë™ì‹œì—)
        print("ğŸ”„ í”„ë¡œê·¸ë¨ ì‹œì‘: ì„œë³´ ëª¨í„° ì‹¤í–‰ ì¤‘...", flush=True)
        logger.info("í”„ë¡œê·¸ë¨ ì‹œì‘: ì„œë³´ ëª¨í„° ìë™ ì‹¤í–‰ (ë¹„ë™ê¸°)")
        try:
            _run_servo_async()
            print("âœ… ì„œë³´ ëª¨í„° ì‹¤í–‰ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)\n", flush=True)
        except Exception as e:
            logger.warning(f"ì„œë³´ ëª¨í„° ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

        # ìŠ¬í”ˆ í†¤ì„ ì‚¬ìš©í•  í‚¤ì›Œë“œ ëª©ë¡
        sad_keywords = [
            "ì£½ê³ ",
            "ìì‚´",
            "ëë‚´ê³ ",
            "ì ˆë§",
            "ê·¹ë„ë¡œ í˜ë“¤",
            "ì‚´ê¸°ì‹«",
            "ë›°ì–´ë‚´ë¦¬",
        ]

        while True:
            # 1. VADë¡œ ìŒì„± ë…¹ìŒ
            temp_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
            temp_wav.close()

            try:
                # Sleep mode: íƒ€ì„ì•„ì›ƒ ì²´í¬
                if not sleep_mode and last_interaction_time:
                    time_since_last = time.time() - last_interaction_time
                    if time_since_last >= SLEEP_TIMEOUT:
                        logger.info(
                            f"Wake mode íƒ€ì„ì•„ì›ƒ ({SLEEP_TIMEOUT}ì´ˆ). Sleep modeë¡œ ì „í™˜í•©ë‹ˆë‹¤."
                        )
                        sleep_mode = True
                        last_interaction_time = None

                # ëª¨ë“œ í‘œì‹œ
                mode_str = "WAKE" if not sleep_mode else "SLEEP"
                logger.debug(f"[{mode_str} MODE] ìŒì„± ì…ë ¥ ëŒ€ê¸° ì¤‘...")

                print("\nğŸ‘‚ ë“£ëŠ” ì¤‘...", end=" ", flush=True)
                indicate_listening(True)

                audio_data = vad.record(
                    on_start=lambda: indicate_listening(True),
                    on_stop=lambda: indicate_listening(False),
                    filename=temp_wav.name,
                )

                indicate_listening(False)

                if not audio_data:
                    print("ğŸ”• (ì¹¨ë¬µ)", flush=True)
                    continue

                # ì˜¤ë””ì˜¤ íŒŒì¼ í¬ê¸° í™•ì¸ (ë””ë²„ê¹…)
                try:
                    file_size = os.path.getsize(temp_wav.name)
                    duration = len(audio_data) / (16000 * 2)  # 16kHz, 16-bit (2 bytes)
                    logger.info(
                        f"ì˜¤ë””ì˜¤ íŒŒì¼: {file_size} bytes, ê¸¸ì´: {duration:.2f}ì´ˆ"
                    )

                    # ë„ˆë¬´ ì§§ì€ ì˜¤ë””ì˜¤ëŠ” ê±´ë„ˆë›°ê¸°
                    if duration < 0.2:
                        logger.warning(
                            f"ì˜¤ë””ì˜¤ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤: {duration:.2f}ì´ˆ (ìµœì†Œ 0.2ì´ˆ í•„ìš”)"
                        )
                        continue
                except Exception as e:
                    logger.debug(f"ì˜¤ë””ì˜¤ íŒŒì¼ ì •ë³´ í™•ì¸ ì‹¤íŒ¨: {e}")

                # 2. STTë¡œ í…ìŠ¤íŠ¸ ë³€í™˜
                print("ğŸ“ ì¸ì‹ ì¤‘...", end=" ", flush=True)
                user_text = stt.recognize_from_file(temp_wav.name)

                if not user_text:
                    print("âŒ ì¸ì‹ ì‹¤íŒ¨", flush=True)
                    continue

                print(f'âœ… ì¸ì‹ë¨: "{user_text}"', flush=True)
                logger.info(f"ì‚¬ìš©ì: {user_text}")

                # Sleep mode: íŠ¸ë¦¬ê±° ë‹¨ì–´ í™•ì¸
                if sleep_mode:
                    if _contains_trigger_word(user_text, trigger_words):
                        logger.info("íŠ¸ë¦¬ê±° ë‹¨ì–´ ê°ì§€! Wake modeë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                        sleep_mode = False
                        last_interaction_time = time.time()
                        # íŠ¸ë¦¬ê±° ë‹¨ì–´ ì œê±° (ì˜ˆ: "ì¹˜í”¼ ì•ˆë…•í•˜ì„¸ìš”" â†’ "ì•ˆë…•í•˜ì„¸ìš”")
                        cleaned_text = user_text
                        for trigger in trigger_words:
                            cleaned_text = cleaned_text.replace(trigger, "", 1).strip()
                        if cleaned_text:
                            user_text = cleaned_text
                        else:
                            # íŠ¸ë¦¬ê±° ë‹¨ì–´ë§Œ ìˆëŠ” ê²½ìš°
                            logger.info("íŠ¸ë¦¬ê±° ë‹¨ì–´ë§Œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            tts.speak(
                                "ë„¤, ë§ì”€í•´ì£¼ì„¸ìš”.", language="ko", style="neutral"
                            )
                            continue
                    else:
                        logger.debug(
                            f"Sleep mode: íŠ¸ë¦¬ê±° ë‹¨ì–´({', '.join(trigger_words)})ê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
                        )
                        continue

                # Wake mode: ìƒí˜¸ì‘ìš© ì‹œê°„ ì—…ë°ì´íŠ¸
                if not sleep_mode:
                    last_interaction_time = time.time()

                # ì¢…ë£Œ ëª…ë ¹ í™•ì¸
                if any(
                    cmd in user_text.lower()
                    for cmd in ["ì¢…ë£Œ", "ëë‚´", "ê·¸ë§Œ", "exit", "quit"]
                ):
                    logger.info("ì¢…ë£Œ ëª…ë ¹ì„ ë°›ì•˜ìŠµë‹ˆë‹¤.")
                    tts.speak("ì•ˆë…•íˆ ê°€ì„¸ìš”!", language="ko", style="neutral")
                    break

                # Sleep ëª…ë ¹ í™•ì¸ (Sleep modeë¡œ ì „í™˜)
                if any(
                    cmd in user_text.lower()
                    for cmd in ["ì˜ì", "sleep", "íœ´ì‹", "ì‰¬ì–´"]
                ):
                    logger.info("Sleep modeë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                    sleep_mode = True
                    last_interaction_time = None
                    continue

                # ì„œë³´ ëª¨í„° ì‹¤í–‰ í‚¤ì›Œë“œ ê°ì§€
                if _contains_servo_keywords(user_text):
                    logger.info("ì„œë³´ ëª¨í„° ì‹¤í–‰ í‚¤ì›Œë“œ ê°ì§€!")
                    print("ğŸ”„ ì„œë³´ ëª¨í„° ì‹¤í–‰ ì¤‘...", flush=True)
                    # ë¹„ë™ê¸°ë¡œ ì‹¤í–‰ (ì„œë³´ ì‹¤í–‰ê³¼ ë™ì‹œì— AI ì‘ë‹µë„ ì²˜ë¦¬ ê°€ëŠ¥)
                    _run_servo_async()
                    print("âœ… ì„œë³´ ëª¨í„° ì‹¤í–‰ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)", flush=True)

                # ìŠ¬í”ˆ í†¤ í‚¤ì›Œë“œ ê°ì§€
                is_sad_topic = any(keyword in user_text for keyword in sad_keywords)
                print(f"ğŸ” ìŠ¬í”ˆ í† í”½ ê°ì§€: {is_sad_topic}", flush=True)

                # 3. AI ì‘ë‹µ ìƒì„±
                print("ğŸ§  ìƒê°í•˜ëŠ” ì¤‘...", end=" ", flush=True)
                brain.add_msg(user_text)
                ai_response = brain.wait_run(
                    ai_name="chipi", device_serial=device_serial
                )
                print("âœ… ì™„ë£Œ", flush=True)
                logger.info(f"AI: {ai_response}")

                if not ai_response:
                    response_style = "sad" if is_sad_topic else "neutral"
                    pitch_shift = -10 if is_sad_topic else 0
                    tts.speak(
                        "ë¯¸ì•ˆ, ë‹¤ì‹œ ë§í•´ì¤„ë˜?",
                        language="ko",
                        style=response_style,
                        pitch_shift=pitch_shift,
                    )
                    continue

                # ì¤‘ë³µ ì‘ë‹µ ë°©ì§€
                if ai_response == last_response:
                    logger.debug("ì´ì „ê³¼ ë™ì¼í•œ ì‘ë‹µì…ë‹ˆë‹¤. TTSë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue

                # 4. ë‹µë³€ ì¶œë ¥ ë° ìŒì„± ì¬ìƒ
                print(f"ğŸ¤– ì¹˜í”¼: {ai_response}")

                # TTS ì¬ìƒ ì‹œì‘ ì‹œ ì‹œê°„ ì—…ë°ì´íŠ¸
                if not sleep_mode:
                    last_interaction_time = time.time()

                # ìŠ¬í”ˆ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìŠ¬í”ˆ í†¤ìœ¼ë¡œ, ì—†ìœ¼ë©´ ì¤‘ë¦½ í†¤ìœ¼ë¡œ ì¬ìƒ
                response_style = "sad" if is_sad_topic else "neutral"
                pitch_shift = -10 if is_sad_topic else 0
                print(f"ğŸ¤ ì‘ë‹µ í†¤: {response_style}, í”¼ì¹˜: {pitch_shift}", flush=True)

                # TTS ì¬ìƒê³¼ ë™ì‹œì— ì„œë³´ ëª¨í„° ì‹¤í–‰ (ë¹„ë™ê¸°)
                _run_servo_async()

                tts.speak(
                    ai_response,
                    language="ko",
                    style=response_style,
                    pitch_shift=pitch_shift,
                )

                # TTS ì¬ìƒ ì™„ë£Œ í›„ ì‹œê°„ ì—…ë°ì´íŠ¸
                if not sleep_mode:
                    last_response = ai_response
                    last_interaction_time = time.time()

            finally:
                # ì„ì‹œ íŒŒì¼ ì‚­ì œ
                try:
                    os.unlink(temp_wav.name)
                except Exception:
                    pass

            # ìµœì†Œí•œì˜ ëŒ€ê¸°
            time.sleep(0.1)

    except KeyboardInterrupt:
        logger.info("\nì‚¬ìš©ìì— ì˜í•´ ì¢…ë£Œë¨")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
        input("ì¢…ë£Œí•˜ë ¤ë©´ ì—”í„°...")
    finally:
        # Board ì •ë¦¬
        if board:
            try:
                board.close()
            except Exception:
                pass


if __name__ == "__main__":
    main()
